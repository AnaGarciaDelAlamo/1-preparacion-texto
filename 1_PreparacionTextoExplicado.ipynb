{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Rf9IfJuVyVKSKIHyTNmxHMSc55XMjdCz",
      "authorship_tag": "ABX9TyOHPZTQdt/vCFdEQVHSetgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnaGarciaDelAlamo/preparacion-texto/blob/main/1_PreparacionTextoExplicado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secuencia - secuencia\n",
        "1.- traductor de texto"
      ],
      "metadata": {
        "id": "n023TTmiun27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxXDTQYDuaX9"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from numpy import array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Método para cargar el txt en memoria\n",
        "def load_doc(filename):\n",
        "  #abrimos el documento en modo lectura\n",
        "  file = open(filename, mode='rt', encoding='utf-8')\n",
        "  #leemos todo el documento\n",
        "  text = file.read()\n",
        "  #cerramos el documento\n",
        "  file.close()\n",
        "  return text"
      ],
      "metadata": {
        "id": "DE_0pUWtu4nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#método para dividir el taxto en líneas y después en frases\n",
        "def to_pairs(doc):\n",
        "  lines = doc.strip().split('\\n')\n",
        "  for i in range(5):\n",
        "    print((lines[i]))\n",
        "  pairs = [line.split('\\t') for line in  lines]\n",
        "  for i in range(5):\n",
        "    print((pairs[i]))\n",
        "  return pairs"
      ],
      "metadata": {
        "id": "akvfrZ9Kvi-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hay que limpiar cada frase. Vamos a hacer las siguientes opraciones de limpieza:\n",
        "#Borrar caracteres no imprimibles\n",
        "#Borrar caracteres de puntuación\n",
        "#Normalizar todos los caracteres: Unicode a ASCII\n",
        "#Cambiar mayúsculas por minúsculas\n",
        "#Borra los caracteres que no sean alfabéticos\n",
        "#Llevar a cabo estas operaciones en cada frase de cada par"
      ],
      "metadata": {
        "id": "jXKffKlRwH4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Método para la limpieza de una lista de líneas\n",
        "def clean_pairs(lines):\n",
        "  cleaned = list()\n",
        "  #preparamos regex para filtrado de caracteres\n",
        "  re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "  re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "  for pair in lines:\n",
        "    clean_pair = list()\n",
        "    for line in pair:\n",
        "      #normalizamos los carateres Unicode\n",
        "      line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "      line = line.decode('UTF-8')\n",
        "      #tokenizamos con espacio en blanco\n",
        "      line = line.split()\n",
        "      #convertimos a minúsculas\n",
        "      line = [word.lower() for word in line]\n",
        "      #borramos la puntuación de cada token\n",
        "      line = [re_punc.sub('', w) for w in line]\n",
        "      #borramos los caracteres no imprimibles de cada token\n",
        "      line = [re_print.sub('', w) for w in line ]\n",
        "      #borramos los token con numeros en ellos\n",
        "      line = [word for word in line if word.isalpha()]\n",
        "      #almacenamos como una cadena\n",
        "      clean_pair.append(' '.join(line))\n",
        "    cleaned.append(clean_pair)\n",
        "  return array(cleaned)"
      ],
      "metadata": {
        "id": "p9ZBZFcfx0n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Método para salvar una lista de frases limpias a un archivo\n",
        "def save_clean_data(sentences, filename):\n",
        "  dump(sentences, open(filename, 'wb'))\n",
        "  print('Saved: %s' % filename)"
      ],
      "metadata": {
        "id": "gm5I3vh8z1lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cargamos el dataset\n",
        "filename = '/content/drive/MyDrive/Datos Nuevas Tecnologías/deu.txt'\n",
        "doc = load_doc(filename)\n",
        "#lo dividimos en parejas inglés-aleman\n",
        "pairs = to_pairs(doc)\n",
        "#limpiamos las frases\n",
        "cleaned = clean_pairs(pairs)\n",
        "#salvamos las parejas limpias a un archivo\n",
        "save_clean_data(cleaned,'/content/drive/MyDrive/Datos Nuevas Tecnologías/english-german.pkl')\n",
        "#comprobamos\n",
        "for i in range(5):\n",
        "  print('[%s] => [%s]' % (cleaned[i,0], cleaned[i,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcNFmi290Ft5",
        "outputId": "1e37a7ea-ab36-434e-e984-cccde3c555d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tGeh.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)\n",
            "Hi.\tHallo!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)\n",
            "Hi.\tGrüß Gott!\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)\n",
            "Run!\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)\n",
            "Run.\tLauf!\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #941078 (Fingerhut)\n",
            "['Go.', 'Geh.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)']\n",
            "['Hi.', 'Hallo!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)']\n",
            "['Hi.', 'Grüß Gott!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)']\n",
            "['Run!', 'Lauf!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)']\n",
            "['Run.', 'Lauf!', 'CC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #941078 (Fingerhut)']\n",
            "Saved: /content/drive/MyDrive/Datos Nuevas Tecnologías/english-german.pkl\n",
            "[go] => [geh]\n",
            "[hi] => [hallo]\n",
            "[hi] => [gru gott]\n",
            "[run] => [lauf]\n",
            "[run] => [lauf]\n"
          ]
        }
      ]
    }
  ]
}